{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea97bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'abc']\n",
      "[b'ab', b'c']\n",
      "[b'abcd']\n",
      "[b'ab', b'cd']\n",
      "[b'ab', b'cd']\n"
     ]
    }
   ],
   "source": [
    "def bpe(mergeable_ranks, token, max_rank=None):\n",
    "    parts = [bytes([b]) for b in token]\n",
    "    while True:\n",
    "        min_idx = None\n",
    "        min_rank = None\n",
    "        for i, pair in enumerate(zip(parts[:-1], parts[1:])):\n",
    "            rank = mergeable_ranks.get(pair[0] + pair[1])\n",
    "            if rank is not None and (min_rank is None or rank < min_rank):\n",
    "                min_idx = i\n",
    "                min_rank = rank\n",
    "        if min_rank is None or (max_rank is not None and min_rank >= max_rank):\n",
    "            break\n",
    "        assert min_idx is not None\n",
    "        parts = parts[:min_idx] + [parts[min_idx] + parts[min_idx + 1]] + parts[min_idx + 2:]\n",
    "    return parts\n",
    "\n",
    "def recover_merges(mergeable_ranks):\n",
    "    merges = {}\n",
    "    for token, rank in mergeable_ranks.items():\n",
    "        if len(token) == 1:\n",
    "            continue\n",
    "        pair = tuple(bpe(mergeable_ranks, token, max_rank=rank))\n",
    "        assert len(pair) == 2, f\"Failed on {token!r} -> {pair}\"\n",
    "        ix0 = mergeable_ranks[pair[0]]\n",
    "        ix1 = mergeable_ranks[pair[1]]\n",
    "        merges[(ix0, ix1)] = rank\n",
    "    return merges\n",
    "\n",
    "# Fake cl100k-style data\n",
    "mergeable_ranks = {\n",
    "    b\"a\": 97,\n",
    "    b\"b\": 98,\n",
    "    b\"c\": 99,\n",
    "    b\"ab\": 256,\n",
    "    b\"abc\": 257,\n",
    "    b\"bc\": 258,\n",
    "}\n",
    "\n",
    "merges = recover_merges(mergeable_ranks)\n",
    "for (a, b), new in merges.items():\n",
    "    print(f\"({a}, {b}) → {new}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a63e1",
   "metadata": {},
   "source": [
    "recover_merges, with help from bpe(), tries to figure out how tiktoken merged bytes together when it built the GPT-4 tokenizer.\n",
    "It is like reverse-engineering (finding the original steps).\n",
    "\n",
    "The GPT-4 tokenizer gives you only the final merged tokens and their ranks (rank = merge order).\n",
    "But it does not give the original merge pairs.\n",
    "\n",
    "recover_merges uses bpe() to simulate merging until the point where a token was created, then it sees which two smaller tokens were combined last. From that, it recreates the missing original merge rules.\n",
    "\n",
    "######\n",
    "recover_merges() answers this question:\n",
    "\"Which two old tokens were glued together to make this new token?\"\n",
    "Tiktoken gives you the final tokens (like \"ing\" → token 1234), but hides which two pieces made it.\n",
    "recover_merges() looks at each final token and says:\n",
    "\n",
    "For \"ing\", it figures out: it was \"in\" + \"g\" that got merged.\n",
    "Then it finds the IDs: \"in\" was 567, \"g\" was 103 → so merge (567, 103) → 1234\n",
    "\n",
    "It does this for every token → rebuilds the full merge table exactly like OpenAI used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae30e4f",
   "metadata": {},
   "source": [
    "# bpe va recover_merges funksiyalari tiktoken kutubxonasidagi tiktoken.get_encoding(\"cl100k_base\") ni qanday qilib \n",
    "# gpt4 cl100k_base lug'atni qurganin aniqlab beradigan funksiyalar yani gpt4 cl100k_base bizga tayyor {\"abc:256} ko'rinish \n",
    "# tayyor lu'gat beradi so'zlar qanday qilib birlashtirilgan haqida info yo'q lekin bpe va recover_merges qanday qilib so'zlar \n",
    "# birlashtirilgan haqida bilib olsa bo'ladi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa741ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
